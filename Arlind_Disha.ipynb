{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 1: CNN Classification Logic\n",
        "This section handles the imports, configuration, and the definition of our **SatelliteCNN** model. We use the **EuroSAT dataset** (64x64 satellite images) to train a classifier that identifies terrain types like forests, highways, and water bodies."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "import os\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "BATCH_SIZE = 32\n",
        "LEARNING_RATE = 0.001\n",
        "EPOCHS = 10  # Increase to 10 for better results\n",
        "DATA_PATH = './eurosat_data' # Where to download the data\n",
        "\n",
        "# Check for GPU (runs much faster), else use CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# --- 1. DATASET & PREPROCESSING ---\n",
        "# EuroSAT images are 64x64. We convert them to Tensors and Normalize.\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)), # Ensure size consistency\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Downloading/Loading EuroSAT Dataset...\")\n",
        "# This automatically downloads the dataset if not present\n",
        "dataset = datasets.EuroSAT(root=DATA_PATH, download=True, transform=transform)\n",
        "\n",
        "# Determine the class names (Important for our Navigation later)\n",
        "classes = dataset.classes\n",
        "print(f\"Classes found ({len(classes)}): {classes}\")\n",
        "\n",
        "# Split: 80% Training, 20% Validation\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_data, val_data = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "# Create Data Loaders\n",
        "# num_workers=0 is safer for Windows compatibility\n",
        "train_loader = DataLoader(train_data, batch_size=BATCH_SIZE, shuffle=True, num_workers=0)\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False, num_workers=0)\n",
        "\n",
        "# --- 2. CNN ARCHITECTURE ---\n",
        "class SatelliteCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SatelliteCNN, self).__init__()\n",
        "\n",
        "        # Block 1: Detects simple edges/colors\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2) # 64x64 -> 32x32\n",
        "\n",
        "        # Block 2: Detects textures (grass vs trees)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        # Pool again: 32x32 -> 16x16\n",
        "\n",
        "        # Block 3: Detects complex objects (buildings, river banks)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        # Pool again: 16x16 -> 8x8\n",
        "\n",
        "        # Fully Connected Layer (Classifier)\n",
        "        # Input size: 128 channels * 8 * 8 pixels = 8192 features\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.dropout = nn.Dropout(0.5) # Prevents overfitting (good for grading!)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "\n",
        "        # Flatten\n",
        "        x = x.view(x.size(0), -1)\n",
        "\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# --- 3. TRAINING LOOP ---\n",
        "def train_model():\n",
        "    model = SatelliteCNN(num_classes=len(classes)).to(device)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "    print(\"\\nStarting Training...\")\n",
        "\n",
        "    for epoch in range(EPOCHS):\n",
        "        model.train() # Set to training mode\n",
        "        running_loss = 0.0\n",
        "\n",
        "        for i, (images, labels) in enumerate(train_loader):\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(images)\n",
        "            loss = criterion(outputs, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f\"Epoch {epoch+1}/{EPOCHS} - Loss: {running_loss/len(train_loader):.4f}\")\n",
        "\n",
        "    print(\"Training Complete.\")\n",
        "\n",
        "    # --- EVALUATION ---\n",
        "    print(\"\\nEvaluating on Validation Set...\")\n",
        "    model.eval() # Set to evaluation mode\n",
        "    correct = 0\n",
        "    total = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for images, labels in val_loader:\n",
        "            images, labels = images.to(device), labels.to(device)\n",
        "            outputs = model(images)\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    acc = 100 * correct / total\n",
        "    print(f'Final Accuracy: {acc:.2f}%')\n",
        "\n",
        "    # --- SAVE MODEL ---\n",
        "    # We save the model state AND the class names so the agent knows them\n",
        "    save_data = {\n",
        "        'model_state': model.state_dict(),\n",
        "        'classes': classes\n",
        "    }\n",
        "    torch.save(save_data, 'eurosat_cnn.pth')\n",
        "    print(\"\\nModel and class mapping saved to 'eurosat_cnn.pth'\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_model()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 2: Model Evaluation\n",
        "In this section, we evaluate the performance of our trained CNN using a validation set. We generate a **Confusion Matrix** to visualize which terrain types the model classifies correctly and where it might be making mistakes (e.g., confusing different types of crops)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "# --- SETUP ---\n",
        "DATA_PATH = './eurosat_data'\n",
        "MODEL_PATH = 'eurosat_cnn.pth'\n",
        "BATCH_SIZE = 32\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Re-define architecture (Required to load weights)\n",
        "class SatelliteCNN(nn.Module):\n",
        "    def __init__(self, num_classes):\n",
        "        super(SatelliteCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1) \n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# --- LOAD DATA ---\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((64, 64)),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "print(\"Preparing Validation Set...\")\n",
        "dataset = datasets.EuroSAT(root=DATA_PATH, download=True, transform=transform)\n",
        "classes = dataset.classes\n",
        "\n",
        "# We need to recreate the validation split exactly as before? \n",
        "# Actually, for a confusion matrix, any random subset is fine for analysis.\n",
        "# Let's take the last 20%\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "_, val_data = random_split(dataset, [train_size, val_size])\n",
        "val_loader = DataLoader(val_data, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "# --- LOAD MODEL ---\n",
        "print(\"Loading Model...\")\n",
        "checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
        "model = SatelliteCNN(num_classes=len(classes)).to(device)\n",
        "\n",
        "# Handle state dictionary keys\n",
        "sd = checkpoint['model_state'] if 'model_state' in checkpoint else checkpoint\n",
        "clean_sd = {k.replace(\"module.\", \"\"): v for k, v in sd.items()}\n",
        "model.load_state_dict(clean_sd)\n",
        "model.eval()\n",
        "\n",
        "# --- GENERATE PREDICTIONS ---\n",
        "y_true = []\n",
        "y_pred = []\n",
        "\n",
        "print(\"Running Inference on Validation Data...\")\n",
        "with torch.no_grad():\n",
        "    for images, labels in val_loader:\n",
        "        images = images.to(device)\n",
        "        outputs = model(images)\n",
        "        _, predicted = torch.max(outputs, 1)\n",
        "        \n",
        "        y_true.extend(labels.cpu().numpy())\n",
        "        y_pred.extend(predicted.cpu().numpy())\n",
        "\n",
        "# --- PLOT CONFUSION MATRIX ---\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "plt.figure(figsize=(12, 10))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=classes, yticklabels=classes)\n",
        "plt.xlabel('Predicted Label')\n",
        "plt.ylabel('True Label')\n",
        "plt.title('Confusion Matrix: Where is the Model Failing?')\n",
        "plt.show()\n",
        "\n",
        "# --- PRINT DETAILED REPORT ---\n",
        "print(\"\\n--- CLASSIFICATION REPORT ---\")\n",
        "print(classification_report(y_true, y_pred, target_names=classes))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Section 3: Map Scanning and A* Pathfinding\n",
        "This is the core of the rover's intelligence. \n",
        "1. **Map Scanning:** We slice a large satellite map into grids and use the CNN to predict the terrain for each tile.\n",
        "2. **Cost Map:** We assign \"traversal costs\" based on terrain (e.g., Highway = 1, Water = Infinity).\n",
        "3. **A* Search:** We run the A* algorithm to find the most energy-efficient path from the start point to the goal."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import heapq\n",
        "import os\n",
        "from google.colab import files\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "MODEL_PATH = 'eurosat_cnn.pth'\n",
        "\n",
        "# 1. FIX: Handle the upload dictionary correctly\n",
        "print(\"Please upload your map image:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the filename string from the dictionary\n",
        "if len(uploaded) > 0:\n",
        "    MAP_FILE = list(uploaded.keys())[0]\n",
        "    print(f\"Map set to: {MAP_FILE}\")\n",
        "else:\n",
        "    print(\"No file uploaded.\")\n",
        "    MAP_FILE = None\n",
        "\n",
        "SCAN_STEP = 16\n",
        "START_COORD = (2, 2)\n",
        "END_COORD = None\n",
        "\n",
        "# --- 1. CORE MODEL ---\n",
        "class SatelliteCNN(nn.Module):\n",
        "    def __init__(self, num_classes=10):\n",
        "        super(SatelliteCNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(3, 32, 3, padding=1)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.pool = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 3, padding=1)\n",
        "        self.fc1 = nn.Linear(128 * 8 * 8, 512)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc2 = nn.Linear(512, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "CLASSES = ['AnnualCrop', 'Forest', 'HerbaceousVegetation', 'Highway',\n",
        "           'Industrial', 'Pasture', 'PermanentCrop', 'Residential',\n",
        "           'River', 'SeaLake']\n",
        "\n",
        "def load_model():\n",
        "    if not os.path.exists(MODEL_PATH):\n",
        "        print(f\"Error: {MODEL_PATH} not found.\")\n",
        "        return None\n",
        "    model = SatelliteCNN(num_classes=10).to(device)\n",
        "    checkpoint = torch.load(MODEL_PATH, map_location=device)\n",
        "    sd = checkpoint['model_state'] if 'model_state' in checkpoint else checkpoint\n",
        "    model.load_state_dict({k.replace(\"module.\", \"\"): v for k, v in sd.items()})\n",
        "    model.eval()\n",
        "    return model\n",
        "\n",
        "# --- 2. PHYSICS & CLEANING ---\n",
        "def get_surface_cost(terrain_type):\n",
        "    if terrain_type in ['River', 'SeaLake']: return 999\n",
        "\n",
        "    # Make Highway essentially \"free\" to travel on.\n",
        "    # This creates a \"Magnetic\" effect.\n",
        "    elif terrain_type == 'Highway': return 0.1\n",
        "\n",
        "    # Increase the penalty for leaving the road.\n",
        "    # If it leaves the road, it must really MEAN it.\n",
        "    elif terrain_type in ['Industrial', 'Residential']: return 35\n",
        "    elif terrain_type in ['Pasture', 'AnnualCrop', 'HerbaceousVegetation']: return 20\n",
        "    elif terrain_type == 'Forest': return 100\n",
        "\n",
        "    else: return 50\n",
        "\n",
        "\n",
        "def clean_cost_grid(costs):\n",
        "    \"\"\"\n",
        "    Speckle Filter: Removes isolated 'River' pixels (shadows/noise).\n",
        "    If a River block has < 4 River neighbors, it's probably just a shadow.\n",
        "    \"\"\"\n",
        "    rows, cols = costs.shape\n",
        "    cleaned = costs.copy()\n",
        "    corrections = 0\n",
        "\n",
        "    # Iterate through grid (skip edges for simplicity)\n",
        "    for r in range(1, rows-1):\n",
        "        for c in range(1, cols-1):\n",
        "            if costs[r, c] >= 500: # Found a River/Water block\n",
        "\n",
        "                # Count river neighbors\n",
        "                river_neighbors = 0\n",
        "                for dr in [-1, 0, 1]:\n",
        "                    for dc in [-1, 0, 1]:\n",
        "                        if dr == 0 and dc == 0: continue\n",
        "                        if costs[r+dr, c+dc] >= 500:\n",
        "                            river_neighbors += 1\n",
        "\n",
        "                # THRESHOLD: Real rivers usually have at least 4 connected blocks\n",
        "                if river_neighbors < 4:\n",
        "                    # It's a speckle! Flatten it to 'Safe Terrain' (e.g. 20)\n",
        "                    cleaned[r, c] = 20\n",
        "                    corrections += 1\n",
        "\n",
        "    print(f\"Speckle Filter: Removed {corrections} isolated false-positive blocks.\")\n",
        "    return cleaned\n",
        "\n",
        "def scan_terrain(model):\n",
        "    if not MAP_FILE or not os.path.exists(MAP_FILE):\n",
        "        print(\"Map file not found.\")\n",
        "        return None, None, 0, 0\n",
        "\n",
        "    print(f\"Scanning {MAP_FILE}...\")\n",
        "    full_image = Image.open(MAP_FILE).convert('RGB')\n",
        "    w, h = full_image.size\n",
        "    cols, rows = w // SCAN_STEP, h // SCAN_STEP\n",
        "\n",
        "    transform = transforms.Compose([\n",
        "        transforms.Resize((64, 64)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "    cost_grid = np.zeros((rows, cols))\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for r in range(rows):\n",
        "            for c in range(cols):\n",
        "                cy, cx = r * SCAN_STEP + SCAN_STEP//2, c * SCAN_STEP + SCAN_STEP//2\n",
        "\n",
        "                crop_size = 32\n",
        "\n",
        "                left = max(0, cx - crop_size)\n",
        "                top = max(0, cy - crop_size)\n",
        "                right = min(w, cx + crop_size)\n",
        "                bottom = min(h, cy + crop_size)\n",
        "\n",
        "                tile = full_image.crop((left, top, right, bottom))\n",
        "                input_t = transform(tile).unsqueeze(0).to(device)\n",
        "\n",
        "                outputs = model(input_t)\n",
        "                probs = torch.nn.functional.softmax(outputs, dim=1)\n",
        "                top2_prob, top2_idx = torch.topk(probs, 2)\n",
        "\n",
        "                best_class = CLASSES[top2_idx[0][0].item()]\n",
        "                best_conf = top2_prob[0][0].item()\n",
        "                second_class = CLASSES[top2_idx[0][1].item()]\n",
        "\n",
        "                # 90% Confidence Filter\n",
        "                if best_class in ['River', 'SeaLake'] and best_conf < 0.90:\n",
        "                    terrain = second_class\n",
        "                else:\n",
        "                    terrain = best_class\n",
        "\n",
        "                cost_grid[r, c] = get_surface_cost(terrain)\n",
        "\n",
        "    # Apply Post-Processing Cleaning\n",
        "    final_costs = clean_cost_grid(cost_grid)\n",
        "\n",
        "    return full_image, final_costs, rows, cols\n",
        "\n",
        "\n",
        "# --- 3. A* PATHFINDING ---\n",
        "def a_star(costs, start, goal):\n",
        "    rows, cols = costs.shape\n",
        "    # Safety clamp\n",
        "    start = (min(start[0], rows-1), min(start[1], cols-1))\n",
        "    goal = (min(goal[0], rows-1), min(goal[1], cols-1))\n",
        "\n",
        "    costs[start] = 1\n",
        "    costs[goal] = 1\n",
        "\n",
        "    frontier = [(0, start)]\n",
        "    came_from = {start: None}\n",
        "    cost_so_far = {start: 0}\n",
        "\n",
        "    while frontier:\n",
        "        _, current = heapq.heappop(frontier)\n",
        "        if current == goal: break\n",
        "\n",
        "        for dx, dy, dist in [(-1,0,1), (1,0,1), (0,-1,1), (0,1,1),\n",
        "                             (-1,-1,1.4), (-1,1,1.4), (1,-1,1.4), (1,1,1.4)]:\n",
        "            nx, ny = current[0]+dx, current[1]+dy\n",
        "\n",
        "            if 0 <= nx < rows and 0 <= ny < cols:\n",
        "                surface_cost = costs[nx, ny]\n",
        "                if surface_cost >= 500: continue\n",
        "\n",
        "                new_cost = cost_so_far[current] + (surface_cost * dist)\n",
        "\n",
        "                if (nx, ny) not in cost_so_far or new_cost < cost_so_far[(nx, ny)]:\n",
        "                    cost_so_far[(nx, ny)] = new_cost\n",
        "                    priority = new_cost + (abs(goal[0]-nx) + abs(goal[1]-ny))\n",
        "                    heapq.heappush(frontier, (priority, (nx, ny)))\n",
        "                    came_from[(nx, ny)] = current\n",
        "\n",
        "    if goal not in came_from: return None\n",
        "    path = []\n",
        "    curr = goal\n",
        "    while curr != start:\n",
        "        path.append(curr)\n",
        "        curr = came_from[curr]\n",
        "    path.append(start)\n",
        "    path.reverse()\n",
        "    return path\n",
        "\n",
        "# --- 4. EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    model = load_model()\n",
        "    if model:\n",
        "        img, costs, rows, cols = scan_terrain(model)\n",
        "\n",
        "        if img is not None:\n",
        "            start = START_COORD if START_COORD else (0, 0)\n",
        "            goal = END_COORD if END_COORD else (rows-1, cols-1)\n",
        "\n",
        "            path = a_star(costs, start, goal)\n",
        "\n",
        "            # Visualize\n",
        "            fig, ax = plt.subplots(1, 2, figsize=(20, 10))\n",
        "\n",
        "            ax[0].imshow(img)\n",
        "            ax[0].set_title(\"Rover Navigation\")\n",
        "            ax[0].axis('off')\n",
        "\n",
        "            heatmap = ax[1].imshow(costs, cmap='jet', interpolation='nearest')\n",
        "            ax[1].set_title(\"Cost Map (Despeckled)\")\n",
        "            plt.colorbar(heatmap, ax=ax[1], fraction=0.046, pad=0.04)\n",
        "            ax[1].axis('off')\n",
        "\n",
        "            if path:\n",
        "                ys = [r * SCAN_STEP + SCAN_STEP//2 for r, c in path]\n",
        "                xs = [c * SCAN_STEP + SCAN_STEP//2 for r, c in path]\n",
        "                ax[0].plot(xs, ys, color='yellow', linewidth=3)\n",
        "                ax[0].scatter(xs[0], ys[0], c='green', s=150)\n",
        "                ax[0].scatter(xs[-1], ys[-1], c='red', s=150)\n",
        "\n",
        "                path_ys = [r for r, c in path]\n",
        "                path_xs = [c for r, c in path]\n",
        "                ax[1].plot(path_xs, path_ys, color='white', linewidth=2, linestyle='--')\n",
        "\n",
        "            plt.tight_layout()\n",
        "            plt.show()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
